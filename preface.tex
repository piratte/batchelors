\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

\section*{The Worldwide LHC Computing Grid}
On the edge of our millenium scientists working on the Large Hadron Collider (LHC) were expecting enormous volumes of data, larger then any single computing centre within the LHC collaboration could handle, so the concept of distributed data management was concieved. In 2001 the CERN Council approved the start of an international collaborative project that consists of a grid-based computer network infrastructure, the Worldwide LHC Computing Grid \cite{happyBday}. 

The WLCG has a hierarchical architecture, where participating sites are cat- egorized according to the resources and services they provide into 4 importance levels called Tiers. Each Tier is represented by a single or distributed computing and storage cluster and provides a specic set of services. The largest centre, CERN data centre or Tier-0, provides the  permanent storage of experimental data and makes the data available for the WLCG processing. Although it provides less than 20\% of the WLCG computing capacity, the role of CERN is unique in keeping one copy of the data from all experiments and for performing the first pass of the data reconstruction. When LHC is not running, Tier-0 reprocesses stored data. The data centre accepts a raw copy of data and stores it localy in CERN, another copy is passed to some Tier-1 center. Tier-1 centers are huge computing centers located in Europe, Canada, USA and Taipei. They provide non-stop support for the Grid, store a share of raw data, perform reprocessing and store its output. They are connetced to CERN with dedicated high-bandwidth optical-fibre links. There are more than 150 Tier-2 centers all around the world, handeling a proportional share of the production and reconstruction of simulated events. Tier-3 centers, which are small local computing clusters at universities or research institutes and even individual PCs \cite{TGrid}.

\section*{Grid Middleware}
When accessing the enormous amounts of data and computing resources, user needs some sort of tool to help him. This software infrastructure is called the middleware, because it connects the application solving users problem and the operating systems of computers. It is a collection of programs and protocols to manage and operate the entire WLCG infrastructure. It provides data and job management, security and information services \cite{GriCom}. The vast variety of re- quirements and needs of the user communities from the four LHC experiments is impossible to meet with only one set of middleware components. Consequently, each experiment user group started developing its own set of tools, which meet their needs. For example AliEn is a middleware solution made by the ALICE ex- periment collaboration. Along with some packages from the WLCG-middleware it provides a complete framework for data analysis according to the ALICE Com- puting model.

\section*{DIRAC}
The Distributed Infrastructure with Remote Agent Control (DIRAC) is a software solution developed for the LHCb experiment. However, the experiments specific features are included as isolated plugins and modules making the whole system more universal \cite{Dir1}.